{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "MzNs_9iuHrZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xE0yyH8L3pTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Mushroom/mushroom_dataset.csv\", sep=\";\")\n",
        "\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "TlXx8dDm2zbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df.shape[1]\n",
        "print(f\"There are {features - 1} features.\")\n",
        "\n",
        "print(\"It is a binary classification problem since the target variable is a class which has two categories - edible(e) or poisonus(p)\")"
      ],
      "metadata": {
        "id": "Q_KWKMvuyKFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_points = (df.shape[0])\n",
        "print(f'{data_points} datapoints.')"
      ],
      "metadata": {
        "id": "3eoC8j9Ez4Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Our dataset has a mix of quantitative and categorical features.\\n-->quantitative features (cap-diameter, stem-height, stem-width).\\n-->categorical features (all others, including target class).\")"
      ],
      "metadata": {
        "id": "1Q6cc_y50OGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[34920:35240]"
      ],
      "metadata": {
        "id": "p0LBRSIT4neB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['class'].value_counts())\n",
        "print(\"\\nClass distribution (percentages):\")\n",
        "print(df['class'].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "id": "6gXEzu98M0Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class_counts = df['class'].value_counts().sort_index()\n",
        "\n",
        "labels = [f'edible', 'poisonous']\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(labels, class_counts.values, color=['skyblue', 'salmon'])\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Class Distribution of Mushrooms')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ATy_wO74PHe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "KtxtfaLA4jsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.keys()"
      ],
      "metadata": {
        "id": "mJDl36yK4rzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "DrgHd0CY4wHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['stem-root', 'veil-type', 'veil-color', 'spore-print-color', 'has-ring'], axis=1, inplace=True)\n",
        "df.shape"
      ],
      "metadata": {
        "id": "s2JS2-mw9KkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "SpDpbxXa-A1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "-ir-3yBuFeOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data = df.select_dtypes(include='number')\n",
        "numerical_features=numerical_data.columns.tolist()\n",
        "print(f'There are {len(numerical_features)} numerical features:', '\\n')\n",
        "print(numerical_features)"
      ],
      "metadata": {
        "id": "5ihM80cb7MSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_data=df.select_dtypes(include= 'object')\n",
        "categorical_features=categorical_data.columns.tolist()\n",
        "print(f'There are {len(categorical_features)} categorical features:', '\\n')\n",
        "print(categorical_features)"
      ],
      "metadata": {
        "id": "2gkeb8_g7gDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['gill-spacing'].fillna('c', inplace=True)\n",
        "df['stem-surface'].fillna('s', inplace=True)\n",
        "df['cap-surface'].fillna('t', inplace=True)\n",
        "df['gill-attachment'].fillna('a', inplace=True)\n",
        "df['ring-type'].fillna('f', inplace=True)"
      ],
      "metadata": {
        "id": "p1o7kvSFG-eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(categorical_features))\n",
        "for _ in categorical_features:\n",
        "  print(f\"{_}{df[_].unique()}\")"
      ],
      "metadata": {
        "id": "1BIKjUjOCXrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "for column in df.columns:\n",
        "    if column not in numerical_features:\n",
        "      df[column] = encoder.fit_transform(df[column].astype(str))"
      ],
      "metadata": {
        "id": "cnEbyRn3DggC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "lD8XfExUFzgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data = df.select_dtypes(include='number')\n",
        "numerical_features=numerical_data.columns.tolist()\n",
        "print(f'There are {len(numerical_features)} numerical features:', '\\n')\n",
        "print(numerical_features)"
      ],
      "metadata": {
        "id": "e1Z8b-N7Dk4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[34920:35240]"
      ],
      "metadata": {
        "id": "1LggxNnfEC3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data.describe().T"
      ],
      "metadata": {
        "id": "uIsPzc0e7kvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_data.describe().T"
      ],
      "metadata": {
        "id": "nwCRrz6i7uTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data.var()"
      ],
      "metadata": {
        "id": "8IU7FJX77wqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data.skew()"
      ],
      "metadata": {
        "id": "MaqzBIQp70EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data.hist(figsize=(12,12),bins=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Prw6ou6-723S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "plt.figure(figsize=(20, 30))\n",
        "\n",
        "for i, col in enumerate(numeric_cols, 1):\n",
        "    plt.subplot(len(numeric_cols), 1, i)\n",
        "    sns.boxplot(x=df[col], color='skyblue')\n",
        "    plt.title(f'Boxplot of {col}', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AAU7HsN676MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data.nunique()"
      ],
      "metadata": {
        "id": "gcJIQHaz8Atl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data.isnull().sum()"
      ],
      "metadata": {
        "id": "lC5ZnA5h8DQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_counts=categorical_data.nunique()\n",
        "print(unique_counts)"
      ],
      "metadata": {
        "id": "35MbVZ-l8F9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in categorical_features:\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    categorical_data[col].value_counts().sort_index().plot(kind='bar', rot=0, xlabel=col,ylabel='count')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7Aq5Nfy_8JAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = numerical_data.corr()\n",
        "correlation_matrix"
      ],
      "metadata": {
        "id": "CPKvblSM8NU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.3f', linewidths=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s3qkdTm_8WqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = 'class'\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(10, 12))\n",
        "\n",
        "corr_pearson = numerical_data.corr(method='pearson')[[target_col]].sort_values(by=target_col, ascending=False)\n",
        "corr_spearman = numerical_data.corr(method='spearman')[[target_col]].sort_values(by=target_col, ascending=False)\n",
        "corr_kendall = numerical_data.corr(method='kendall')[[target_col]].sort_values(by=target_col, ascending=False)\n",
        "\n",
        "titles = ['Pearson Correlation', 'Spearman Correlation', 'Kendall Correlation']\n",
        "correlations = [corr_pearson, corr_spearman, corr_kendall]\n",
        "\n",
        "for ax, corr, title in zip(axes, correlations, titles):\n",
        "    sns.heatmap(corr, ax=ax, annot=True, cmap=\"coolwarm\", cbar=False, fmt=\".2f\")\n",
        "    ax.set_title(title, fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xeadDfTLKwI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts=df.groupby(\"class\").size()\n",
        "\n",
        "columns=['class','count','percentage']\n",
        "outcome=[0,1]\n",
        "count=list()\n",
        "percentage=list()\n",
        "\n",
        "for val in range(2):\n",
        "    count.append(class_counts[val])\n",
        "    percent=(class_counts[val]/105000)*100\n",
        "    percentage.append(percent)\n",
        "\n",
        "imbalance_df=pd.DataFrame(list(zip(outcome,count,percentage)),columns=columns)\n",
        "imbalance_df"
      ],
      "metadata": {
        "id": "Js1VG0FNMBTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_data.plot(kind='density', figsize=(14,14), subplots=True, layout=(4,4), title=\"Density plot of Numerical features\", sharex=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y67Atd51Mj4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y)"
      ],
      "metadata": {
        "id": "tj4me8DWI8BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots()\n",
        "ax.hist(y_train)\n",
        "ax.set_xlabel('class label')\n",
        "ax.set_ylabel('no of instances')\n",
        "ax.grid(True)"
      ],
      "metadata": {
        "id": "_pIQldDpJUoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)"
      ],
      "metadata": {
        "id": "IEzc2TBsJW5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "A1lmN3oaJYPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=6)"
      ],
      "metadata": {
        "id": "UhkBPB8DJY5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "UgGFqihOJc3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_KNN = knn.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "accuracy_KNN = accuracy_score(y_test, y_pred_KNN)\n",
        "print(\"Accuracy k-nearest neighbors(KNN) = %f \" % (accuracy_KNN * 100) + '%')\n",
        "\n",
        "error_KNN = 1 - accuracy_KNN\n",
        "print(\"Error k-nearest neighbors(KNN) = %f \" % (error_KNN * 100) + '%')"
      ],
      "metadata": {
        "id": "o3Y3te8GJeW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_test, y_pred_KNN)\n",
        "report = classification_report(y_test, y_pred_KNN)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "-WDxPscpJgew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train, y_train)\n",
        "y_pred_decision_tree = clf.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
        "print(\"Accuracy Decision Tree = %f \" % (accuracy_decision_tree * 100) + '%')\n",
        "\n",
        "error_decision_tree = 1 - accuracy_decision_tree\n",
        "print(\"Error Decision Tree = %f \" % (error_decision_tree * 100) + '%')"
      ],
      "metadata": {
        "id": "Bxt9UaiwJi85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_test, y_pred_decision_tree)\n",
        "report = classification_report(y_test, y_pred_decision_tree)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "2NZ23UOBJjyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "model_MLP = MLPClassifier()\n",
        "model_MLP.fit(X_train, y_train)\n",
        "pred_MLP = model_MLP.predict(X_test)\n",
        "accuracy_neural = accuracy_score(y_test, pred_MLP)\n",
        "print(\"Accuracy neural = %f \" % (accuracy_neural * 100) + '%')\n",
        "\n",
        "error_neural = 1 - accuracy_neural\n",
        "print(\"Error neural = %f \" % (error_neural * 100) + '%')"
      ],
      "metadata": {
        "id": "aPRPA2i9JrE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_test, pred_MLP)\n",
        "report = classification_report(y_test, pred_MLP)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "4PgNOgJAJtpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['KNN', 'Decision Tree', \"Neural Network\"]\n",
        "values = [accuracy_KNN, accuracy_decision_tree, accuracy_neural]\n",
        "\n",
        "plt.bar(categories, values, width= 0.6)\n",
        "plt.xlabel(\"Models\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Prediction Accuracy\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(alpha=0.2)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rZfKEGL9Jzfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "clusters = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "sil_score = silhouette_score(X_scaled, clusters)\n",
        "print(f\"Silhouette score for KMeans (k=2): {sil_score:.4f}\")\n",
        "\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12,5))\n",
        "axes[0].scatter(X_pca[:,0], X_pca[:,1], c=clusters, cmap='tab10', s=8)\n",
        "axes[0].set_title('KMeans Clusters (k=2)')\n",
        "axes[0].set_xlabel('PC1'); axes[0].set_ylabel('PC2')\n",
        "\n",
        "axes[1].scatter(X_pca[:,0], X_pca[:,1], c=y, cmap='tab10', s=8)\n",
        "axes[1].set_title('True Labels')\n",
        "axes[1].set_xlabel('PC1'); axes[1].set_ylabel('PC2')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "contingency = pd.crosstab(clusters, y, rownames=['cluster'], colnames=['true_label'])\n",
        "print(\"Contingency table (clusters vs true labels):\")\n",
        "print(contingency)\n"
      ],
      "metadata": {
        "id": "cSwTGWv3nYxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Shapes:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
      ],
      "metadata": {
        "id": "ZvWHLlf77yzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, roc_curve, confusion_matrix, classification_report,\n",
        "    log_loss\n",
        ")\n",
        "\n",
        "models = {\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=6),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, solver='liblinear'),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Neural Network': MLPClassifier(max_iter=500, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    elif hasattr(model, \"decision_function\"):\n",
        "        try:\n",
        "            df_scores = model.decision_function(X_test)\n",
        "            y_proba = (df_scores - df_scores.min()) / (df_scores.max() - df_scores.min() + 1e-8)\n",
        "        except:\n",
        "            y_proba = None\n",
        "    else:\n",
        "        y_proba = None\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
        "    ll = log_loss(y_test, y_proba) if y_proba is not None else None\n",
        "\n",
        "    results.append({\n",
        "        'model': name,\n",
        "        'accuracy': acc,\n",
        "        'precision': prec,\n",
        "        'recall': rec,\n",
        "        'f1': f1,\n",
        "        'auc': auc,\n",
        "        'log_loss': ll,\n",
        "        'y_pred': y_pred,\n",
        "        'y_proba': y_proba,\n",
        "        'estimator': model\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame([{\n",
        "    'model': r['model'],\n",
        "    'accuracy': r['accuracy'],\n",
        "    'precision': r['precision'],\n",
        "    'recall': r['recall'],\n",
        "    'f1': r['f1'],\n",
        "    'auc': r['auc'],\n",
        "    'log_loss': r['log_loss']\n",
        "} for r in results]).set_index('model')\n",
        "\n",
        "display(metrics_df.sort_values('accuracy', ascending=False))\n"
      ],
      "metadata": {
        "id": "1Z07KpJ68a4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "metrics_df['accuracy'].plot(kind='bar')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.ylim(0,1)\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WjEefF_X8hPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "ind = np.arange(len(metrics_df))\n",
        "width = 0.35\n",
        "\n",
        "ax.bar(ind - width/2, metrics_df['precision'], width, label='Precision')\n",
        "ax.bar(ind + width/2, metrics_df['recall'], width, label='Recall')\n",
        "ax.set_xticks(ind)\n",
        "ax.set_xticklabels(metrics_df.index, rotation=45, ha='right')\n",
        "ax.set_ylim(0,1)\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Precision and Recall by Model')\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6y_ehG328_hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "for r in results:\n",
        "    name = r['model']\n",
        "    y_proba = r['y_proba']\n",
        "    if y_proba is not None:\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "        auc = roc_auc_score(y_test, y_proba)\n",
        "        plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n",
        "    else:\n",
        "        print(f\"Skipping ROC for {name} (no probability scores available)\")\n",
        "\n",
        "plt.plot([0,1], [0,1], linestyle='--', alpha=0.6)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(alpha=0.2)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XRLPK1WH9D2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for r in results:\n",
        "    name = r['model']\n",
        "    y_pred = r['y_pred']\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(4,3))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix: {name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Classification report for {name}:\\n\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "    print(\"-\"*60)\n"
      ],
      "metadata": {
        "id": "HUCIUX6l9Jj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df_rounded = metrics_df.round(4)\n",
        "display(metrics_df_rounded)"
      ],
      "metadata": {
        "id": "-YPNqvag9TMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "for column in X.columns:\n",
        "    if X[column].dtype == 'object':\n",
        "      X[column] = encoder.fit_transform(X[column].astype(str))\n",
        "\n",
        "y = encoder.fit_transform(y.astype(str))\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "linreg = LinearRegression().fit(X_train, y_train)\n",
        "residuals = y_train - linreg.predict(X_train)\n",
        "outlier_threshold = 3*np.std(residuals)\n",
        "outliers = np.abs(residuals) > outlier_threshold\n",
        "\n",
        "linreg_score = 0\n",
        "\n",
        "if np.all(outliers):\n",
        "    print(\"All samples are outliers, cannot fit a linear regression model\")\n",
        "else:\n",
        "    X_train_cleaned, y_train_cleaned = X_train[~outliers], y_train[~outliers]\n",
        "\n",
        "    linreg_cleaned = LinearRegression().fit(X_train_cleaned, y_train_cleaned)\n",
        "\n",
        "    y_pred_cleaned = linreg_cleaned.predict(X_test)\n",
        "\n",
        "    mse_cleaned = mean_squared_error(y_test, y_pred_cleaned)\n",
        "    rmse_cleaned = np.sqrt(mse_cleaned)\n",
        "    mae = mean_absolute_error(y_test, y_pred_cleaned)\n",
        "\n",
        "    r2_score_cleaned = r2_score(y_test, y_pred_cleaned) * 100\n",
        "\n",
        "    linreg_score = r2_score_cleaned\n",
        "    linreg_mae = mae\n",
        "\n",
        "    print(f\"Mean Squared Error (MSE):{mse_cleaned:.2f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE):{rmse_cleaned:.2f}\")\n",
        "    print(f\"Mean Absolute Error (MAE) {mae:.2f}\")\n",
        "    print(\" \")\n",
        "    print(f\"R-squared (RÂ²):{r2_score_cleaned:.6f}%\")"
      ],
      "metadata": {
        "id": "H0LiUEMJ9Y37"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}